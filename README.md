# Transformers.js チュートリアル

ブラウザ上でAI・機械学習モデルを動かすためのTransformers.jsのチュートリアルです。

## Transformers.jsとは

### 概要

**Transformers.js**は、最先端の機械学習モデルをJavaScript環境で実行できるライブラリです。Hugging Faceが開発したPython向けの**Transformers**ライブラリをWebブラウザやNode.js向けに移植したもので、サーバーを必要とせずにクライアントサイドで完結する革新的なソリューションです。

### 主な特徴

#### 🌐 完全なクライアントサイド実行
- **サーバー不要**: すべての処理がブラウザ内で完結
- **プライバシー保護**: データが外部サーバーに送信されない
- **低コスト**: サーバーインフラが不要で運用コストを削減
- **高速レスポンス**: ネットワーク遅延がなく、リアルタイム処理が可能

#### ⚡ 高性能な実装
- **WebAssembly (WASM)**: ネイティブに近い実行速度
- **ONNX Runtime**: 最適化された推論エンジン
- **モデルキャッシング**: 一度ダウンロードしたモデルをブラウザにキャッシュ
- **量子化モデル**: モデルサイズを削減し、高速化

#### 🎯 豊富なタスク対応
- **自然言語処理 (NLP)**: テキスト分類、質問応答、翻訳、要約など
- **コンピュータビジョン (CV)**: 画像分類、物体検出、セグメンテーション
- **音声処理**: 音声認識、音声分類
- **マルチモーダル**: 画像キャプション生成など

## できること

### テキスト処理
- **感情分析**: テキストの感情（ポジティブ/ネガティブ）を判定
- **テキスト分類**: ニュース記事のカテゴリ分類、スパム検出など
- **質問応答**: 文章から質問に対する回答を抽出
- **翻訳**: 多言語間の自動翻訳
- **要約**: 長文を短く要約
- **固有表現認識**: 人名、地名、組織名などを抽出
- **テキスト生成**: 文章の続きを自動生成

### 画像処理
- **画像分類**: 画像が何であるかを識別
- **物体検出**: 画像内の物体を検出し位置を特定
- **セグメンテーション**: ピクセル単位で画像を分類
- **画像キャプション**: 画像の内容を文章で説明
- **ゼロショット分類**: 学習していないカテゴリでも分類可能

### 音声処理
- **音声認識**: 音声をテキストに変換
- **音声分類**: 音声の内容や話者を分類
- **音声翻訳**: 音声を別言語のテキストに変換

### マルチモーダル
- **画像からテキスト**: 画像の説明文を自動生成
- **ビジュアル質問応答**: 画像に関する質問に回答
- **ドキュメント理解**: 文書画像から情報を抽出

## 技術的基盤

### 1. Transformer アーキテクチャ

Transformers.jsの核心技術は、2017年にGoogleが発表した **「Attention Is All You Need」** 論文で提案された**Transformerアーキテクチャ**です。

#### Self-Attention メカニズム
- 入力シーケンス内の各要素間の関係性を学習
- 長距離依存関係を効率的に捉える
- 並列処理が可能で学習・推論が高速

#### エンコーダー・デコーダー構造
- **エンコーダー**: 入力を理解し、意味表現に変換
- **デコーダー**: 意味表現から出力を生成
- タスクに応じてエンコーダーのみ、デコーダーのみの使用も可能

### 2. 事前学習済みモデル (Pre-trained Models)

#### Transfer Learning（転移学習）
大規模なデータセットで事前学習したモデルを、特定のタスクに適用する手法です。

**代表的な事前学習モデル:**

##### BERT (Bidirectional Encoder Representations from Transformers)
- **開発**: Google (2018年)
- **特徴**: 双方向の文脈を理解
- **用途**: テキスト分類、質問応答、固有表現認識
- **学習方法**: Masked Language Modeling (MLM)

##### GPT (Generative Pre-trained Transformer)
- **開発**: OpenAI
- **特徴**: 自己回帰的なテキスト生成
- **用途**: テキスト生成、対話システム
- **学習方法**: 次単語予測

##### T5 (Text-to-Text Transfer Transformer)
- **開発**: Google (2019年)
- **特徴**: すべてのタスクをテキスト生成として統一
- **用途**: 翻訳、要約、質問応答など

##### Vision Transformer (ViT)
- **開発**: Google (2020年)
- **特徴**: Transformerを画像処理に適用
- **用途**: 画像分類、物体検出
- **革新**: CNNに頼らない純粋なTransformer

##### Whisper
- **開発**: OpenAI (2022年)
- **特徴**: 多言語音声認識
- **用途**: 音声文字起こし、音声翻訳
- **学習**: 68万時間の多言語音声データ

##### CLIP (Contrastive Language-Image Pre-training)
- **開発**: OpenAI (2021年)
- **特徴**: 画像とテキストの関係を学習
- **用途**: ゼロショット画像分類、画像検索

### 3. ONNX Runtime Web

#### ONNX (Open Neural Network Exchange)
- マイクロソフト、Facebook（Meta）らが開発したオープン標準
- 異なるフレームワーク間でモデルを相互運用
- PyTorch、TensorFlowなどのモデルをONNX形式に変換

#### ONNX Runtime Web
- **WebAssembly (WASM)**: ネイティブに近い実行速度
- **WebGL**: GPU加速による高速推論
- **量子化**: モデルサイズと計算量を削減
- **最適化**: グラフ最適化により推論を高速化

### 4. Hugging Face エコシステム

#### Model Hub
- **30万以上のモデル**: コミュニティが公開
- **簡単なアクセス**: モデル名を指定するだけで利用可能
- **バージョン管理**: Gitベースのモデル管理
- **ライセンス管理**: 各モデルのライセンス情報を明示

#### Tokenizers
- **高速**: Rustで実装された高速トークナイザー
- **サブワード分割**: BPE、WordPiece、SentencePieceなど
- **多言語対応**: 100以上の言語に対応

### 5. 量子化技術

モデルサイズを削減し、推論を高速化する技術です。

#### 量子化の種類
- **INT8量子化**: 32bit浮動小数点 → 8bit整数
- **動的量子化**: 重みのみを量子化
- **静的量子化**: 重みと活性化を量子化

#### メリット
- **モデルサイズ**: 75%削減（FP32 → INT8）
- **推論速度**: 2〜4倍高速化
- **メモリ使用量**: 大幅削減

### 6. マルチタスク学習

一つのモデルで複数のタスクを学習する手法です。

#### メリット
- **汎化性能の向上**: 関連タスクから学習
- **効率的**: 一つのモデルで多用途
- **知識の転移**: タスク間で知識を共有

## 学術的・技術的成果の活用

### 深層学習の基礎理論
- **バックプロパゲーション**: 効率的な学習
- **最適化アルゴリズム**: Adam、AdamWなど
- **正則化**: Dropout、Layer Normalization

### 自然言語処理の進化
- **Word2Vec (2013)**: 単語の分散表現
- **ELMo (2018)**: 文脈を考慮した単語表現
- **BERT (2018)**: 双方向Transformer
- **GPT系列**: 大規模言語モデル

### コンピュータビジョンの進化
- **CNN**: 畳み込みニューラルネットワーク
- **ResNet**: 残差接続による深層化
- **Vision Transformer**: Transformerの画像への適用
- **DETR**: Transformerによる物体検出

### マルチモーダル学習
- **CLIP**: 画像とテキストの統合学習
- **DALL-E**: テキストから画像生成
- **Flamingo**: 視覚言語モデル

## 実用的な応用例

### ビジネス
- **カスタマーサポート**: 自動応答システム
- **コンテンツモデレーション**: 不適切コンテンツの検出
- **商品推薦**: ユーザーの嗜好分析
- **文書分析**: 契約書や報告書の自動処理

### 教育
- **自動採点**: 記述問題の採点支援
- **学習支援**: 個別化された学習コンテンツ
- **言語学習**: リアルタイム翻訳・発音チェック

### アクセシビリティ
- **音声文字起こし**: 聴覚障害者支援
- **画像説明**: 視覚障害者向け画像の音声説明
- **リアルタイム翻訳**: 言語の壁を超えたコミュニケーション

### クリエイティブ
- **コンテンツ生成**: 記事の下書き、要約作成
- **画像タグ付け**: 自動メタデータ生成
- **動画字幕**: 自動字幕生成

## なぜTransformers.jsが重要か

### プライバシーファースト
データがクライアント側で処理されるため、機密情報が外部に漏れるリスクがありません。医療、金融、法務などの分野で特に重要です。

### コスト削減
サーバーインフラが不要なため、API使用料やサーバー維持費が削減できます。スタートアップや個人開発者にも利用しやすくなります。

### 民主化されたAI
誰でも無料で最先端のAIモデルを利用でき、AIの民主化に貢献しています。学習や実験のハードルが大幅に下がります。

### オフライン動作
一度モデルをダウンロードすれば、インターネット接続なしで動作します。ネットワークが不安定な環境や、オフライン必須のアプリケーションに最適です。

## 使用している基盤モデル

このチュートリアルでは、以下のHugging Face事前学習済みモデル（ONNX形式）を使用しています：

### 第1章：感情分析
- **モデル**: `Xenova/bert-base-multilingual-uncased-sentiment`
- **基盤**: BERT (Bidirectional Encoder Representations from Transformers)
- **特徴**: 多言語対応の感情分析モデル、1〜5つ星の評価を出力

### 第2章：テキスト分類
- **モデル**: デフォルトのゼロショット分類モデル（Facebook BART-large-mnli）
- **基盤**: BART (Bidirectional and Auto-Regressive Transformers)
- **特徴**: 学習していないカテゴリでも分類可能なゼロショット学習

### 第3章：質問応答
- **モデル**: デフォルトのQAモデル（DistilBERT）
- **基盤**: DistilBERT (蒸留されたBERT)
- **特徴**: BERTを軽量化したモデル、高速な質問応答

### 第4章：物体検出
- **モデル**: `Xenova/detr-resnet-50`
- **基盤**: DETR (DEtection TRansformer) + ResNet-50
- **特徴**: Transformerベースの物体検出、COCO 80クラスに対応

### 第5章：音声認識
- **モデル**: `Xenova/whisper-small`
- **基盤**: Whisper (OpenAI)
- **特徴**: 多言語音声認識、日本語を含む100言語以上に対応

### 第6章：画像キャプション生成
- **モデル1**: `Xenova/vit-gpt2-image-captioning`
  - **基盤**: Vision Transformer (ViT) + GPT-2
  - **特徴**: 画像から英語のキャプションを生成
- **モデル2**: `Xenova/nllb-200-distilled-600M`
  - **基盤**: NLLB (No Language Left Behind, Meta)
  - **特徴**: 200言語対応の翻訳モデル、英語→日本語翻訳に使用

> **重要**: すべてのモデルはHugging Face Model Hubから自動的にダウンロードされ、ブラウザにキャッシュされます。

## 目次

### [第1章：はじめてのTransformers.js](./chapter01/README.md)
- Transformers.jsとは
- セットアップ方法
- 感情分析の基本サンプル

### [第2章：テキスト分類](./chapter02/README.md)
- パイプラインの基本
- テキスト分類モデルの使用
- カスタム閾値の設定

### [第3章：質問応答システム](./chapter03/README.md)
- Question Answeringモデル
- コンテキストから回答を抽出
- 複数の質問への対応

### [第4章：画像処理](./chapter04/README.md)
- 画像分類
- 物体検出
- バウンディングボックスの描画

### [第5章：音声処理](./chapter05/README.md)
- 音声認識（Speech-to-Text）
- 音声の前処理
- リアルタイム音声入力

### [第6章：高度な応用](./chapter06/README.md)
- テキスト生成
- 画像キャプション生成
- マルチモーダルモデルの活用

## 更新履歴

### 2025-10-06
- 初版作成
- 全6章のチュートリアルを追加
